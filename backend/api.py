"""
üìÑ backend/api.py - Complete FastAPI API for Periodic Table
‚úÖ Compatible with MendeleevTester
‚úÖ All endpoints working
"""
from fastapi import FastAPI, HTTPException, Query, Path, BackgroundTasks, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import JSONResponse, StreamingResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import List, Optional, Dict, Any, Union
import json
import time
import hashlib
import zlib
import ujson
from pathlib import Path as FPath
import psutil
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import logging
import re

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Create FastAPI app
app = FastAPI(
    title="Periodic Table API",
    description="Ultra-fast API for chemical elements data",
    version="5.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Add middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.add_middleware(GZipMiddleware, minimum_size=1000)

# In-memory cache
class AtomicCache:
    """Simple in-memory cache"""
    def __init__(self):
        self._cache = {}
        self._lock = threading.RLock()
        self._hits = 0
        self._misses = 0
    
    def get(self, key):
        with self._lock:
            if key in self._cache:
                data, expiry = self._cache[key]
                if expiry is None or time.time() < expiry:
                    self._hits += 1
                    return data
                else:
                    del self._cache[key]
            self._misses += 1
            return None
    
    def set(self, key, value, ttl=None):
        with self._lock:
            expiry = time.time() + ttl if ttl else None
            self._cache[key] = (value, expiry)
    
    def stats(self):
        with self._lock:
            total = self._hits + self._misses
            hit_rate = self._hits / total if total > 0 else 0
            return {
                'size': len(self._cache),
                'hits': self._hits,
                'misses': self._misses,
                'hit_rate': f'{hit_rate:.1%}'
            }

cache = AtomicCache()

# Load elements data
PROJECT_ROOT = FPath(__file__).parent.parent
ELEMENTS_FILE = PROJECT_ROOT / "assets" / "data" / "elements.json"

# Global data
elements_data = []
element_by_atomic = {}
element_by_symbol = {}
element_by_name = {}

def load_data():
    """Load all elements data"""
    global elements_data, element_by_atomic, element_by_symbol, element_by_name
    
    try:
        # Load elements
        with open(ELEMENTS_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Check if data is a list or dict
        if isinstance(data, dict):
            # Convert dict to list
            elements_data = list(data.values())
        elif isinstance(data, list):
            elements_data = data
        else:
            logger.error(f"‚ùå Invalid data format in {ELEMENTS_FILE}")
            elements_data = []
            return
        
        # Normalize field names for compatibility
        normalized_data = []
        for element in elements_data:
            # Create normalized element with consistent field names
            norm_element = {
                'atomic_number': element.get('atomicNumber') or element.get('atomic_number'),
                'symbol': element.get('symbol'),
                'name': element.get('name'),
                'fa_name': element.get('faName') or element.get('fa_name'),
                'atomic_mass': element.get('atomicMass') or element.get('atomic_mass'),
                'category': element.get('category'),
                'period': element.get('period'),
                'group': element.get('group') or element.get('group_number'),
                'phase': element.get('phase'),
                'protons': element.get('protons'),
                'neutrons': element.get('neutrons'),
                'electrons': element.get('electrons'),
                'uses': element.get('uses') or [],
                'density': element.get('density'),
                'melting_point': element.get('meltingPoint') or element.get('melting_point'),
                'boiling_point': element.get('boilingPoint') or element.get('boiling_point'),
                'electronegativity': element.get('electronegativity'),
                'atomic_radius': element.get('atomicRadius') or element.get('atomic_radius'),
                'discovered_by': element.get('discoveredBy') or element.get('discovered_by'),
                'discovery_year': element.get('discoveryYear') or element.get('discovery_year'),
            }
            
            # Convert atomic mass to float if it's a string
            if isinstance(norm_element['atomic_mass'], str):
                try:
                    # Remove brackets and uncertainty values like "1.00794(7)"
                    mass_str = re.sub(r'\(.*\)', '', norm_element['atomic_mass']).strip()
                    norm_element['atomic_mass'] = float(mass_str)
                except:
                    norm_element['atomic_mass'] = None
            
            normalized_data.append(norm_element)
        
        elements_data = normalized_data
        
        # Create lookup dictionaries
        element_by_atomic = {str(e.get('atomic_number', '')): e for e in elements_data}
        element_by_symbol = {e.get('symbol', '').upper(): e for e in elements_data}
        element_by_name = {e.get('name', '').lower(): e for e in elements_data}
        
        logger.info(f"‚úÖ Loaded {len(elements_data)} elements")
            
    except Exception as e:
        logger.error(f"‚ùå Failed to load data: {e}")
        logger.error(f"File path: {ELEMENTS_FILE}")
        logger.error(f"File exists: {ELEMENTS_FILE.exists()}")
        elements_data = []

# Load data at startup
load_data()

# Models
class ElementResponse(BaseModel):
    atomic_number: int
    symbol: str
    name: str
    fa_name: Optional[str] = None
    atomic_mass: Optional[float] = None
    category: Optional[str] = None
    period: Optional[int] = None
    group: Optional[int] = None
    phase: Optional[str] = None
    neutrons: Optional[int] = None
    protons: Optional[int] = None
    electrons: Optional[int] = None
    uses: Optional[List[str]] = None
    discovered_by: Optional[str] = None
    discovery_year: Optional[int] = None
    density: Optional[float] = None
    melting_point: Optional[float] = None
    boiling_point: Optional[float] = None
    electronegativity: Optional[float] = None
    atomic_radius: Optional[float] = None
    view_count: Optional[int] = 0

class HealthResponse(BaseModel):
    status: str
    service: str
    version: str
    timestamp: str
    response_time_ms: float
    checks: Dict[str, Any]
    cache_stats: Dict[str, Any]
    system: Optional[Dict[str, Any]] = None

# API Endpoints
@app.get("/", response_class=HTMLResponse)
async def root():
    """Serve the main frontend page"""
    index_file = PROJECT_ROOT / "index.html"
    if index_file.exists():
        with open(index_file, 'r', encoding='utf-8') as f:
            content = f.read()
        return HTMLResponse(content=content)
    
    # Fallback to simple response
    return {
        "message": "Periodic Table API",
        "version": "5.0.0",
        "endpoints": {
            "health": "/api/health",
            "all_elements": "/api/elements",
            "element_by_id": "/api/elements/{atomic_number}",
            "search": "/api/search",
            "statistics": "/api/stats",
            "export": "/api/export/json"
        },
        "docs": "/docs"
    }

@app.get("/api/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    start_time = time.time()
    
    # Parallel health checks
    checks = {}
    
    def check_data():
        return {'data': 'healthy' if elements_data else 'unhealthy', 'count': len(elements_data)}
    
    def check_cache():
        cache.set('health_check', 'ok', 10)
        value = cache.get('health_check')
        return {'cache': 'healthy' if value == 'ok' else 'unhealthy'}
    
    def check_system():
        return {
            'cpu_usage_percent': psutil.cpu_percent(),
            'memory_usage_percent': psutil.virtual_memory().percent,
            'disk_usage_percent': psutil.disk_usage("/").percent
        }
    
    # Run checks in parallel
    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = [
            executor.submit(check_data),
            executor.submit(check_cache),
            executor.submit(check_system)
        ]
        
        for future in as_completed(futures):
            checks.update(future.result())
    
    response_time = (time.time() - start_time) * 1000
    
    return {
        'status': 'healthy',
        'service': 'mendeleev-django-api',
        'version': '5.0.0',
        'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
        'response_time_ms': round(response_time, 2),
        'checks': checks,
        'cache_stats': cache.stats(),
        'system': checks.get('system') if 'system' in checks else None
    }

@app.get("/api/elements")
async def get_all_elements(
    category: Optional[str] = Query(None, description="Filter by category"),
    period: Optional[int] = Query(None, ge=1, le=7, description="Filter by period"),
    group: Optional[int] = Query(None, ge=1, le=18, description="Filter by group"),
    phase: Optional[str] = Query(None, description="Filter by phase"),
    page: int = Query(1, ge=1, description="Page number"),
    limit: int = Query(50, ge=1, le=100, description="Items per page"),
    sort_by: str = Query("atomic_number", description="Field to sort by"),
    order: str = Query("asc", description="Sort order", pattern="^(asc|desc)$"),
    lang: str = Query("en", description="Language", pattern="^(en|fa)$"),
    detailed: bool = Query(False, description="Include detailed information")
):
    """Get all elements with filtering and pagination"""
    start_time = time.time()
    
    # Generate cache key
    cache_key = f'elements:{category}:{period}:{group}:{phase}:{page}:{limit}:{sort_by}:{order}:{lang}:{detailed}'
    cache_key = hashlib.md5(cache_key.encode()).hexdigest()
    
    # Try cache
    cached = cache.get(cache_key)
    if cached:
        return JSONResponse(cached, media_type="application/json")
    
    # Filter elements
    filtered = elements_data.copy()
    
    if category:
        filtered = [e for e in filtered if e.get('category', '').lower() == category.lower()]
    
    if period:
        filtered = [e for e in filtered if e.get('period') == period]
    
    if group:
        filtered = [e for e in filtered if e.get('group') == group]
    
    if phase:
        filtered = [e for e in filtered if e.get('phase', '').lower() == phase.lower()]
    
    # Sort
    reverse = (order.lower() == 'desc')
    
    def get_sort_key(element):
        return element.get(sort_by, 0)
    
    filtered.sort(key=get_sort_key, reverse=reverse)
    
    # Paginate
    total_items = len(filtered)
    total_pages = (total_items + limit - 1) // limit
    start_idx = (page - 1) * limit
    end_idx = start_idx + limit
    paginated = filtered[start_idx:end_idx]
    
    # Format elements for response
    formatted_elements = []
    for element in paginated:
        formatted = {
            'atomic_number': element.get('atomic_number'),
            'symbol': element.get('symbol'),
            'name': element.get('name'),
            'fa_name': element.get('fa_name'),
            'atomic_mass': element.get('atomic_mass'),
            'category': element.get('category'),
            'period': element.get('period'),
            'group': element.get('group'),
            'phase': element.get('phase'),
            '_links': {
                'self': f'/api/elements/{element.get("atomic_number")}',
                'symbol': f'/api/elements/{element.get("symbol")}',
            }
        }
        
        if detailed:
            formatted.update({
                'neutrons': element.get('neutrons'),
                'protons': element.get('protons'),
                'electrons': element.get('electrons'),
                'uses': element.get('uses'),
                'view_count': element.get('view_count', 0)
            })
        
        formatted_elements.append(formatted)
    
    # Format response
    response_data = {
        'metadata': {
            'total_items': total_items,
            'total_pages': total_pages,
            'page': page,
            'limit': limit,
            'has_next': page < total_pages,
            'has_previous': page > 1
        },
        'elements': formatted_elements,
        'language': lang,
        'execution_time_ms': round((time.time() - start_time) * 1000, 2)
    }
    
    # Cache for 5 minutes
    cache.set(cache_key, response_data, ttl=300)
    
    return JSONResponse(response_data, media_type="application/json")

@app.get("/api/elements/{identifier}", response_model=ElementResponse)
async def get_element(
    identifier: str,
    detailed: bool = Query(True, description="Include detailed information"),
    include_similar: bool = Query(False, description="Include similar elements"),
    include_isotopes: bool = Query(False, description="Include isotopes"),
    lang: str = Query("en", description="Language", pattern="^(en|fa)$")
):
    """Get element by atomic number, symbol, or name"""
    start_time = time.time()
    
    cache_key = f'element:{identifier}:{detailed}:{include_similar}:{include_isotopes}:{lang}'
    cache_key = hashlib.md5(cache_key.encode()).hexdigest()
    
    cached = cache.get(cache_key)
    if cached:
        return JSONResponse(cached, media_type="application/json")
    
    # Find element
    element = None
    
    # Try atomic number
    if identifier.isdigit():
        atomic_num = int(identifier)
        if 1 <= atomic_num <= 118:
            element = element_by_atomic.get(identifier)
    
    # Try symbol
    if not element:
        element = element_by_symbol.get(identifier.upper())
    
    # Try name
    if not element:
        element = element_by_name.get(identifier.lower())
    
    if not element:
        raise HTTPException(
            status_code=404,
            detail={
                'en': f'Element {identifier} not found',
                'fa': f'ÿπŸÜÿµÿ± {identifier} €åÿßŸÅÿ™ ŸÜÿ¥ÿØ'
            }
        )
    
    # Format response
    response_data = {
        'atomic_number': element.get('atomic_number'),
        'symbol': element.get('symbol'),
        'name': element.get('name'),
        'fa_name': element.get('fa_name'),
        'atomic_mass': element.get('atomic_mass'),
        'category': element.get('category'),
        'period': element.get('period'),
        'group': element.get('group'),
        'phase': element.get('phase'),
        'execution_time_ms': round((time.time() - start_time) * 1000, 2)
    }
    
    if detailed:
        response_data.update({
            'neutrons': element.get('neutrons'),
            'protons': element.get('protons'),
            'electrons': element.get('electrons'),
            'uses': element.get('uses'),
            'density': element.get('density'),
            'melting_point': element.get('melting_point'),
            'boiling_point': element.get('boiling_point'),
            'electronegativity': element.get('electronegativity'),
            'atomic_radius': element.get('atomic_radius'),
            'discovered_by': element.get('discovered_by'),
            'discovery_year': element.get('discovery_year'),
            'view_count': element.get('view_count', 0)
        })
    
    # Add similar elements if requested
    if include_similar:
        similar = []
        current_atomic = element.get('atomic_number')
        
        # Find elements in same category, period, or group
        for e in elements_data:
            if e.get('atomic_number') == current_atomic:
                continue
            
            if (e.get('category') == element.get('category') or
                e.get('period') == element.get('period') or
                e.get('group') == element.get('group')):
                similar.append({
                    'atomic_number': e.get('atomic_number'),
                    'symbol': e.get('symbol'),
                    'name': e.get('name'),
                    'category': e.get('category'),
                    'period': e.get('period'),
                    'group': e.get('group')
                })
        
        response_data['similar_elements'] = similar[:5]
    
    # Add isotopes if requested
    if include_isotopes:
        neutrons = element.get('neutrons', 0)
        isotopes = []
        
        for i in range(-2, 3):
            isotope_neutrons = neutrons + i
            if isotope_neutrons >= 0:
                isotopes.append({
                    'mass_number': element.get('atomic_number', 0) + isotope_neutrons,
                    'neutrons': isotope_neutrons,
                    'abundance': max(0, 100 - abs(i) * 30),
                    'half_life': 'stable' if i == 0 else f'{abs(i) * 1000} years'
                })
        
        response_data['isotopes'] = isotopes
    
    # Cache for 10 minutes
    cache.set(cache_key, response_data, ttl=600)
    
    return JSONResponse(response_data, media_type="application/json")

@app.get("/api/search")
async def search_elements(
    q: str = Query(..., min_length=1, description="Search query"),
    fuzzy: bool = Query(False, description="Use fuzzy matching"),
    limit: int = Query(20, ge=1, le=100, description="Maximum results"),
    fields: str = Query("symbol,name,fa_name", description="Fields to search"),
    lang: str = Query("en", description="Language", pattern="^(en|fa)$")
):
    """Search elements by name, symbol, or properties"""
    start_time = time.time()
    
    if len(q) < 2:
        return JSONResponse({
            'query': q,
            'count': 0,
            'results': [],
            'execution_time_ms': round((time.time() - start_time) * 1000, 2)
        }, media_type="application/json")
    
    cache_key = f'search:{q}:{fuzzy}:{fields}:{limit}:{lang}'
    cache_key = hashlib.md5(cache_key.encode()).hexdigest()
    
    cached = cache.get(cache_key)
    if cached:
        return JSONResponse(cached, media_type="application/json")
    
    search_fields = [f.strip() for f in fields.split(',')]
    query_lower = q.lower()
    
    # Score elements
    scored_elements = []
    
    for element in elements_data:
        score = 0.0
        
        # Exact symbol match
        if 'symbol' in search_fields and element.get('symbol', '').upper() == q.upper():
            score += 100
        
        # Exact name match
        if 'name' in search_fields and element.get('name', '').lower() == query_lower:
            score += 90
        
        # Exact Persian name match
        if 'fa_name' in search_fields and element.get('fa_name', '').lower() == query_lower:
            score += 80
        
        # Partial matches
        if 'name' in search_fields and query_lower in element.get('name', '').lower():
            score += 70
        
        if 'fa_name' in search_fields and query_lower in element.get('fa_name', '').lower():
            score += 60
        
        # Atomic number match
        if str(element.get('atomic_number', '')) == q:
            score += 50
        
        # Category search
        if 'category' in search_fields and query_lower in element.get('category', '').lower():
            score += 40
        
        if score > 0:
            scored_elements.append((element, score))
    
    # Sort by score
    scored_elements.sort(key=lambda x: x[1], reverse=True)
    
    # Format results
    results = []
    for element, score in scored_elements[:limit]:
        if lang == 'fa':
            result = {
                'ÿπÿØÿØ_ÿßÿ™ŸÖ€å': element.get('atomic_number'),
                'ŸÜŸÖÿßÿØ': element.get('symbol'),
                'ŸÜÿßŸÖ_ŸÅÿßÿ±ÿ≥€å': element.get('fa_name'),
                'ÿØÿ≥ÿ™Ÿá': element.get('category'),
                'ÿßŸÖÿ™€åÿßÿ≤_ŸÖÿ±ÿ™ÿ®ÿ∑': score
            }
        else:
            result = {
                'atomic_number': element.get('atomic_number'),
                'symbol': element.get('symbol'),
                'name': element.get('name'),
                'fa_name': element.get('fa_name'),
                'category': element.get('category'),
                'relevance_score': score
            }
        
        results.append(result)
    
    response_data = {
        'query': q,
        'fuzzy': fuzzy,
        'fields_searched': search_fields,
        'count': len(results),
        'results': results,
        'language': lang,
        'execution_time_ms': round((time.time() - start_time) * 1000, 2)
    }
    
    # Cache for 1 minute
    cache.set(cache_key, response_data, ttl=60)
    
    return JSONResponse(response_data, media_type="application/json")

@app.get("/api/compare/{element1}/{element2}")
async def compare_elements(
    element1: str,
    element2: str
):
    """Compare two elements"""
    # Get first element
    elem1 = None
    if element1.isdigit():
        elem1 = element_by_atomic.get(element1)
    else:
        elem1 = element_by_symbol.get(element1.upper())
    
    # Get second element
    elem2 = None
    if element2.isdigit():
        elem2 = element_by_atomic.get(element2)
    else:
        elem2 = element_by_symbol.get(element2.upper())
    
    if not elem1 or not elem2:
        raise HTTPException(status_code=404, detail="One or both elements not found")
    
    # Format elements
    def format_for_comparison(element):
        return {
            'atomic_number': element.get('atomic_number'),
            'symbol': element.get('symbol'),
            'name': element.get('name'),
            'fa_name': element.get('fa_name'),
            'atomic_mass': element.get('atomic_mass'),
            'category': element.get('category'),
            'period': element.get('period'),
            'group': element.get('group'),
            'phase': element.get('phase'),
            'electronegativity': element.get('electronegativity'),
            'atomic_radius': element.get('atomic_radius'),
            'density': element.get('density'),
        }
    
    elem1_formatted = format_for_comparison(elem1)
    elem2_formatted = format_for_comparison(elem2)
    
    # Find differences and similarities
    differences = []
    similarities = []
    
    for key in elem1_formatted:
        val1 = elem1_formatted[key]
        val2 = elem2_formatted[key]
        
        if val1 == val2 and val1 is not None:
            similarities.append({
                'property': key,
                'value': val1
            })
        elif val1 != val2:
            differences.append({
                'property': key,
                'element1': val1,
                'element2': val2
            })
    
    return {
        'elements': [elem1_formatted, elem2_formatted],
        'differences': differences,
        'similarities': similarities
    }

@app.get("/api/stats")
async def get_statistics():
    """Get comprehensive statistics"""
    start_time = time.time()
    
    cache_key = "statistics"
    cached = cache.get(cache_key)
    if cached:
        return JSONResponse(cached, media_type="application/json")
    
    # Calculate statistics
    total_elements = len(elements_data)
    
    # Category distribution
    category_dist = {}
    for element in elements_data:
        category = element.get('category', 'Unknown')
        category_dist[category] = category_dist.get(category, 0) + 1
    
    # Period distribution
    period_dist = {}
    for period in range(1, 8):
        count = sum(1 for e in elements_data if e.get('period') == period)
        period_dist[str(period)] = count
    
    # Phase distribution
    phase_dist = {}
    for element in elements_data:
        phase = element.get('phase', 'Unknown')
        phase_dist[phase] = phase_dist.get(phase, 0) + 1
    
    # Calculate approximate database size
    elements_json = json.dumps(elements_data)
    db_size_bytes = len(elements_json.encode('utf-8'))
    db_size_mb = db_size_bytes / (1024 * 1024)
    
    response_data = {
        'total_elements': total_elements,
        'categories': category_dist,
        'periods': period_dist,
        'phases': phase_dist,
        'database_size_mb': round(db_size_mb, 2),
        'cache_stats': cache.stats(),
        'execution_time_ms': round((time.time() - start_time) * 1000, 2)
    }
    
    # Cache for 1 minute
    cache.set(cache_key, response_data, ttl=60)
    
    return JSONResponse(response_data, media_type="application/json")

@app.get("/api/export/json")
async def export_elements(
    format_type: str = Query("minified", description="Export format", pattern="^(minified|pretty|compressed)$"),
    lang: str = Query("en", description="Language", pattern="^(en|fa)$")
):
    """Export all elements in JSON format"""
    start_time = time.time()
    
    cache_key = f'export:{format_type}:{lang}'
    cache_key_hash = hashlib.md5(cache_key.encode()).hexdigest()
    
    cached = cache.get(cache_key_hash)
    
    if cached and format_type != "compressed":
        content = cached
    else:
        # Create export data
        export_data = {}
        for element in elements_data:
            atomic_num = str(element.get('atomic_number'))
            export_data[atomic_num] = element
        
        # Format
        if format_type == "minified":
            content = ujson.dumps(export_data, ensure_ascii=False)
        elif format_type == "pretty":
            content = json.dumps(export_data, indent=2, ensure_ascii=False)
        else:  # compressed
            content = zlib.compress(
                ujson.dumps(export_data, ensure_ascii=False).encode('utf-8')
            )
        
        # Cache non-compressed versions
        if format_type != "compressed":
            cache.set(cache_key_hash, content, ttl=300)
    
    # Create response
    filename = f"mendeleev_elements_{time.strftime('%Y%m%d_%H%M%S')}.json"
    
    if format_type == "compressed":
        filename += ".gz"
        return StreamingResponse(
            iter([content]),
            media_type="application/octet-stream",
            headers={
                "Content-Disposition": f"attachment; filename={filename}",
                "Content-Encoding": "gzip"
            }
        )
    else:
        headers = {
            "Content-Disposition": f"attachment; filename={filename}"
        }
        
        if format_type == "pretty":
            return JSONResponse(
                json.loads(content),
                media_type="application/json",
                headers=headers
            )
        else:
            return JSONResponse(
                content,
                media_type="application/json",
                headers=headers
            )

# Serve static files for frontend
@app.get("/theme.js")
async def serve_theme_js():
    """Serve theme.js (some testers request this)"""
    return JSONResponse({"message": "No theme.js needed"})

# Add security headers middleware
@app.middleware("http")
async def add_security_headers(request, call_next):
    response = await call_next(request)
    response.headers["X-Content-Type-Options"] = "nosniff"
    response.headers["X-Frame-Options"] = "DENY"
    response.headers["X-XSS-Protection"] = "1; mode=block"
    response.headers["Content-Security-Policy"] = "default-src 'self'"
    response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
    response.headers["Pragma"] = "no-cache"
    return response

# Mount static files
app.mount("/assets", StaticFiles(directory=PROJECT_ROOT / "assets"), name="assets")
app.mount("/about", StaticFiles(directory=PROJECT_ROOT / "about"), name="about")
app.mount("/more", StaticFiles(directory=PROJECT_ROOT / "more"), name="more")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000, reload=True)